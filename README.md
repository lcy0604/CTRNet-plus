# CTRNet++

This repository is the implementation of "CTRNet++: Dual-path Learning with Local-global Context Modeling for Scene Text Removal", which is published on TOMM 2024. [paper](https://dl.acm.org/doi/abs/10.1145/3697837)

The training and inference codes are available. 

<!-- We  updated our retrained model weights on Jul 27. You can download it [Here](https://drive.google.com/file/d/1Z6i9RNVJ3EoAAaS0jC3tldQUhSzlu5Ar/view?usp=sharing). -->

For any questions, please email to me at [liuchongyu1996@gmail.com](mailto:liuchongyu1996@gmail.com). Thank you for your interest. 

## Environment
My environment can be refered as follows:
- Python 3.8.11
- PyTorch 1.8.0
- Polygon
- shapely
- skimage

## Datasets
We use [SCUT-EnsText](https://github.com/HCIILAB/SCUT-EnsText) and [SCUT-Syn](https://github.com/HCIILAB/Scene-Text-Removal). 

All the images are set to 512 * 512. The strucuture images for LCG block are generated by the official code in [RTV methods](http://www.cse.cuhk.edu.hk/~leojia/projects/texturesep/). You can generate the data yourselves, and we will also provide the test data here. [data](https://drive.google.com/file/d/1U4WMlD6MW_x0y7-KE2ILxYDnvUBk8lfg/view?usp=sharing). 

After downloading the dataset, you can directly place the folders as 

```bash
data/
--SCUT-ENS
----train
------image/*.jpg
------label/*.jpg
------mask/*.jpg
------gt/*.txt

----test
------image/*.jpg
------label/*.jpg
------mask/*.jpg
------gt/*.txt
...
```

The mask can be generated using the gt by OpenCV (```cv2.drawContours```), the example are shown in [here](https://github.com/lcy0604/EraseNet/tree/master/example/mask).

## Training 
Create an new directory (```./pretrained/```) and place the pretrain weights for FFC-based inpainting model--LaMa, VGG-16, and our pretrain model for structure generator. All of them are available at [here](https://drive.google.com/drive/folders/14xqLRXzJB10z6GF2fMw8O_kwN-qhilOD?usp=sharing).  You can also retrain the structure generator yoursellf.

``` bash
CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 --master_port=8942 --use_env \
    main.py \
    --train_dataset scutens_train \
    --val_dataset scutens_test \
    --data_root ./data/ \
    --output_dir ./checkpoint/ \
    --batch_size 4 \
    --lr 0.0005 \
    --num_workers 8 \
    --code_dir . \
    --epochs 300 \
    --save_interval 10 \
    --warmup_epochs 10 \
    --dataset_file erase \
    --rotate_max_angle 10 \
    --rotate_prob 0.3 \
    --crop_min_ratio 0.7 \
    --crop_max_ratio 1.0 \
    --crop_prob 1.0 \
    --pixel_embed_dim 512 \
    --train     
```


## Testing 
For generating the results with text removal, the commond is as follows:

```bash
CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --nproc_per_node=1 --master_port=8941 --use_env \
    main.py \
    --train_dataset scutens_train \
    --val_dataset scutens_test \
    --data_root ./data/ \
    --output_dir ./checkpoint/ \
    --batch_size 1 \
    --num_workers 0 \
    --code_dir . \
    --dataset_file erase \
    --eval \
    --resume your/checkpoint/file
```

<!-- We provide one of our [models](https://github.com/lcy0604/CTRNet-plus) trained on SCUT-ENS for testing, which can obtain 35.54 PSNR. The results reported in the paper are from   -->

## Acknowledge

The repository is benefit a lot from [DETR](https://github.com/facebookresearch/detr), [Lama](https://github.com/advimman/lama), [SPL](https://github.com/WendongZh/SPL), [ResTormer](https://github.com/swz30/Restormer), and [CTSDG](https://github.com/xiefan-guo/ctsdg). Thanks a lot for their excellent work.

## Citation
If you find our method or dataset useful for your reserach, please cite:
```
@article{CTRNetpp,
        author = {Liu, Chongyu and Peng, Dezhi and Liu, Yuliang and Jin, Lianwen},
        title = {CTRNet++: Dual-path Learning with Local-global Context Modeling for Scene Text Removal},
        year = {2024},
        publisher = {Association for Computing Machinery},
        address = {New York, NY, USA},
        issn = {1551-6857},
        url = {https://doi.org/10.1145/3697837},
        doi = {10.1145/3697837},
        note = {Just Accepted},
        journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
        month = oct,
        keywords = {Scene Text Removal, Context Guidance, Dual-path Learning}
}
```

## Feedback
Suggestions and opinions of our work (both positive and negative) are welcome. Please contact the authors by sending email to Chongyu Liu([liuchongyu1996@gmail.com](mailto:liuchongyu1996@gmail.com)). For commercial usage, please contact Prof. Lianwen Jin via ([eelwjin@scut.edu.cn](mailto:eelwjin@scut.edu.cn)).
